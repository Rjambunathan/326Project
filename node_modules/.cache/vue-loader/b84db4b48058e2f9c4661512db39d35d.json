{"remainingRequest":"/Users/andrewsmith/Computer Science/School/CompSci326/326Project/node_modules/vue-loader/lib/index.js??vue-loader-options!/Users/andrewsmith/Computer Science/School/CompSci326/326Project/src/components/Enrollment.vue?vue&type=script&lang=js&","dependencies":[{"path":"/Users/andrewsmith/Computer Science/School/CompSci326/326Project/src/components/Enrollment.vue","mtime":1575525475440},{"path":"/Users/andrewsmith/Computer Science/School/CompSci326/326Project/node_modules/cache-loader/dist/cjs.js","mtime":499162500000},{"path":"/Users/andrewsmith/Computer Science/School/CompSci326/326Project/node_modules/babel-loader/lib/index.js","mtime":499162500000},{"path":"/Users/andrewsmith/Computer Science/School/CompSci326/326Project/node_modules/cache-loader/dist/cjs.js","mtime":499162500000},{"path":"/Users/andrewsmith/Computer Science/School/CompSci326/326Project/node_modules/vue-loader/lib/index.js","mtime":499162500000}],"contextDependencies":[],"result":[{"type":"Buffer","data":"base64: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"},{"version":3,"sources":["Enrollment.vue"],"names":[],"mappings":";;;;;;;;AAQA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","file":"Enrollment.vue","sourceRoot":"src/components","sourcesContent":["<template>\n    <div>\n        <video muted id=\"video\" width=\"100%\" height=\"100%\" autoplay></video>\n        <canvas id=\"frame\" width=\"640\" height=\"480\"></canvas>\n    </div>\n</template>\n\n<script>\n    /* eslint-disable no-console */\n    export default {\n        name: 'Enrollment'\n    }\n    // Prefer camera resolution nearest to 1280x720.\n    //import * as faceapi from \"../assets/face-api.min\";\n\n    // implements nodejs wrappers for HTMLCanvasElement, HTMLImageElement, ImageData\n    //import * as canvas from 'canvas';\n\n    import * as faceapi from 'face-api.js';\n\n    // patch nodejs environment, we need to provide an implementation of\n    // HTMLCanvasElement and HTMLImageElement, additionally an implementation\n    // of ImageData is required, in case you want to use the MTCNN\n    //const { Canvas, Image, ImageData } = canvas\n    //faceapi.env.monkeyPatch({ Canvas, Image, ImageData })\n\n    // Promise.all([\n    //     faceapi.nets.tinyFaceDetector.loadFromUri('/models'),\n    //     faceapi.nets.faceLandmark68Net.loadFromUri('/models'),\n    //     faceapi.nets.faceRecognitionNet.loadFromUri('/models'),\n    //     faceapi.nets.faceExpressionNet.loadFromUri('/models')\n    // ]).then(startLiveVideo);\n\n    loadModels = async () => {\n        const MODEL_URL = \"/models\";\n        await faceapi.loadSsdMobilenetv1Model(MODEL_URL);\n        await faceapi.loadFaceLandmarkModel(MODEL_URL);\n        await faceapi.loadFaceRecognitionModel(MODEL_URL);\n    };\n    startLiveVideo();\n\n\n    function startLiveVideo() {\n        // Prefer camera resolution nearest to 1280x720.\n        var video;\n        var constraints = { audio: false, video: { width: 1280, height: 720 } };\n\n\n        navigator.mediaDevices.getUserMedia(constraints)\n            .then(function(mediaStream) {\n                video = document.querySelector('video');\n                video.srcObject = mediaStream;\n                video.onloadedmetadata = function() {\n                    video.play();\n                };\n                video.addEventListener('play', () => {\n                    const canvas = faceapi.createCanvasFromMedia(video);\n                    document.body.append(canvas);\n                    //NEED TO FIGURE OUT DYNAMIC HEIGHT AND WIDTH\n                    const displaySize = { width: \"1280\", height: \"720\" };\n                    faceapi.matchDimensions(canvas, displaySize);\n                    setInterval(async () => {\n                        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();\n                        const resizedDetections = faceapi.resizeResults(detections, displaySize);\n                        canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);\n                        faceapi.draw.drawDetections(canvas, resizedDetections);\n                        faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);\n                        faceapi.draw.drawFaceExpressions(canvas, resizedDetections);\n                    }, 300)\n                });\n            })\n            .catch(function(err) { console.log(err.name + \": \" + err.message); });\n    }\n\n</script>\n\n<style scoped>\n    body {\n        margin: 0;\n        padding: 0;\n        /*width: 100vw;*/\n        /*height: 100vh;*/\n        display: flex;\n        justify-content: center;\n        align-items: center;\n    }\n    canvas {\n        position: absolute;\n    }\n</style>\n"]}]}