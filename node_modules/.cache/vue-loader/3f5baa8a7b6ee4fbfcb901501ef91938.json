{"remainingRequest":"/Users/andrewsmith/Computer Science/School/CompSci326/326Project/node_modules/vue-loader/lib/index.js??vue-loader-options!/Users/andrewsmith/Computer Science/School/CompSci326/326Project/src/components/Enrollment.vue?vue&type=script&lang=js&","dependencies":[{"path":"/Users/andrewsmith/Computer Science/School/CompSci326/326Project/src/components/Enrollment.vue","mtime":1575235812864},{"path":"/Users/andrewsmith/Computer Science/School/CompSci326/326Project/node_modules/cache-loader/dist/cjs.js","mtime":499162500000},{"path":"/Users/andrewsmith/Computer Science/School/CompSci326/326Project/node_modules/babel-loader/lib/index.js","mtime":499162500000},{"path":"/Users/andrewsmith/Computer Science/School/CompSci326/326Project/node_modules/cache-loader/dist/cjs.js","mtime":499162500000},{"path":"/Users/andrewsmith/Computer Science/School/CompSci326/326Project/node_modules/vue-loader/lib/index.js","mtime":499162500000}],"contextDependencies":[],"result":[{"type":"Buffer","data":"base64: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"},{"version":3,"sources":["Enrollment.vue"],"names":[],"mappings":";;;;;;;;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;;AAGA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA","file":"Enrollment.vue","sourceRoot":"src/components","sourcesContent":["<template>\n    <div>\n        <video muted id=\"video\" width=\"100%\" height=\"100%\" autoplay></video>\n        <canvas id=\"frame\" width=\"640\" height=\"480\"></canvas>\n    </div>\n</template>\n\n<script>\n    /* eslint-disable no-console */\n    export default {\n        name: 'Enrollment'\n    }\n    // Prefer camera resolution nearest to 1280x720.\n    var video;\n    var constraints = { audio: false, video: { width: 1280, height: 720 } };\n\n\n    navigator.mediaDevices.getUserMedia(constraints)\n        .then(function(mediaStream) {\n            video = document.querySelector('video');\n            video.srcObject = mediaStream;\n            video.onloadedmetadata = function() {\n                video.play();\n            };\n        })\n        .catch(function(err) { console.log(err.name + \": \" + err.message); }); // always check for errors at the end.\n\n    //---------------------\n    // TAKE A SNAPSHOT CODE\n    //---------------------\n\n    // implements nodejs wrappers for HTMLCanvasElement, HTMLImageElement, ImageData\n\n    import * as canvas from 'canvas';\n\n    import * as faceapi from 'face-api.js';\n    // // patch nodejs environment, we need to provide an implementation of\n    // // HTMLCanvasElement and HTMLImageElement, additionally an implementation\n    // // of ImageData is required, in case you want to use the MTCNN\n\n    var frame, ctx;\n    const { Canvas, Image, ImageData } = canvas;\n    const MODEL_URL = './assets/models';\n\n    faceapi.env.monkeyPatch({ Canvas, Image, ImageData });\n\n\n    window.setInterval(function(){\n       snapshot();\n    }, 1000);\n\n    async function snapshot() {\n        frame = document.getElementById(\"frame\");\n        ctx = frame.getContext('2d');\n        // Draws current image from the video element into the canvas\n        ctx.drawImage(video, 0,0, frame.width, frame.height);\n\n        await faceDetectionNet.loadFromDisk('../../weights');\n        await faceapi.nets.faceLandmark68Net.loadFromDisk('../../weights');\n        await faceapi.nets.faceRecognitionNet.loadFromDisk('../../weights');\n\n        const resultsRef = await faceapi.detectAllFaces(frame, faceDetectionOptions)\n            .withFaceLandmarks();\n            .withFaceDescriptors();\n        console.log(detections);\n    }\n</script>\n\n<style scoped>\n\n</style>\n"]}]}